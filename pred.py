# -*- coding: utf-8 -*-
"""stock-market-analysis-prediction-using-lstm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hgv7QIn4bJziUTS6T0HRGfMQvqaASGAV
"""


# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('whitegrid')
plt.style.use("fivethirtyeight")
# %matplotlib inline

from pandas_datareader.data import DataReader
import yfinance as yf
from pandas_datareader import data as pdr

yf.pdr_override()

from datetime import datetime


#tech_list = ['AAPL', 'GOOG', 'MSFT', 'AMZN']
#
#tech_list = ['AAPL', 'GOOG', 'MSFT', 'AMZN']
#
#end = datetime.now()
#start = datetime(end.year - 1, end.month, end.day)
#
#for stock in tech_list:
#    globals()[stock] = yf.download(stock, start, end)
#
#
#company_list = [AAPL, GOOG, MSFT, AMZN]
#company_name = ["APPLE", "GOOGLE", "MICROSOFT", "AMAZON"]
#
#for company, com_name in zip(company_list, company_name):
#    company["company_name"] = com_name
#
#df = pd.concat(company_list, axis=0)
#df.tail(10)
#
#AAPL.describe()
#
#AAPL.info()
#
#plt.figure(figsize=(15, 10))
#plt.subplots_adjust(top=1.25, bottom=1.2)
#
#for i, company in enumerate(company_list, 1):
#    plt.subplot(2, 2, i)
#    company['Adj Close'].plot()
#    plt.ylabel('Adj Close')
#    plt.xlabel(None)
#    plt.title(f"Closing Price of {tech_list[i - 1]}")
#
#plt.tight_layout()
#
#plt.figure(figsize=(15, 10))
#plt.subplots_adjust(top=1.25, bottom=1.2)
#
#for i, company in enumerate(company_list, 1):
#    plt.subplot(2, 2, i)
#    company['Volume'].plot()
#    plt.ylabel('Volume')
#    plt.xlabel(None)
#    plt.title(f"Sales Volume for {tech_list[i - 1]}")
#
#plt.tight_layout()
#
#ma_day = [10, 20, 50]
#
#for ma in ma_day:
#    for company in company_list:
#        column_name = f"MA for {ma} days"
#        company[column_name] = company['Adj Close'].rolling(ma).mean()
#
#
#fig, axes = plt.subplots(nrows=2, ncols=2)
#fig.set_figheight(10)
#fig.set_figwidth(15)
#
#AAPL[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,0])
#axes[0,0].set_title('APPLE')
#
#GOOG[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,1])
#axes[0,1].set_title('GOOGLE')
#
#MSFT[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,0])
#axes[1,0].set_title('MICROSOFT')
#
#AMZN[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,1])
#axes[1,1].set_title('AMAZON')
#
#fig.tight_layout()
#
#for company in company_list:
#    company['Daily Return'] = company['Adj Close'].pct_change()
#
#fig, axes = plt.subplots(nrows=2, ncols=2)
#fig.set_figheight(10)
#fig.set_figwidth(15)
#
#AAPL['Daily Return'].plot(ax=axes[0,0], legend=True, linestyle='--', marker='o')
#axes[0,0].set_title('APPLE')
#
#GOOG['Daily Return'].plot(ax=axes[0,1], legend=True, linestyle='--', marker='o')
#axes[0,1].set_title('GOOGLE')
#
#MSFT['Daily Return'].plot(ax=axes[1,0], legend=True, linestyle='--', marker='o')
#axes[1,0].set_title('MICROSOFT')
#
#AMZN['Daily Return'].plot(ax=axes[1,1], legend=True, linestyle='--', marker='o')
#axes[1,1].set_title('AMAZON')
#
#fig.tight_layout()
#
#plt.figure(figsize=(12, 9))
#
#for i, company in enumerate(company_list, 1):
#    plt.subplot(2, 2, i)
#    company['Daily Return'].hist(bins=50)
#    plt.xlabel('Daily Return')
#    plt.ylabel('Counts')
#    plt.title(f'{company_name[i - 1]}')
#
#plt.tight_layout()
#
#closing_df = pdr.get_data_yahoo(tech_list, start=start, end=end)['Adj Close']
#tech_rets = closing_df.pct_change()
#tech_rets.head()
#
#sns.jointplot(x='GOOG', y='GOOG', data=tech_rets, kind='scatter', color='seagreen')
#
#sns.jointplot(x='GOOG', y='MSFT', data=tech_rets, kind='scatter')
#
#sns.pairplot(tech_rets, kind='reg')
#
#return_fig = sns.PairGrid(tech_rets.dropna())
#
#return_fig.map_upper(plt.scatter, color='purple')
#return_fig.map_lower(sns.kdeplot, cmap='cool_d')
#
#return_fig.map_diag(plt.hist, bins=30)
#
#returns_fig = sns.PairGrid(closing_df)
#
#returns_fig.map_upper(plt.scatter,color='purple')
#
#returns_fig.map_lower(sns.kdeplot,cmap='cool_d')
#
#returns_fig.map_diag(plt.hist,bins=30)
#
#plt.figure(figsize=(12, 10))
#
#plt.subplot(2, 2, 1)
#sns.heatmap(tech_rets.corr(), annot=True, cmap='summer')
#plt.title('Correlation of stock return')
#
#plt.subplot(2, 2, 2)
#sns.heatmap(closing_df.corr(), annot=True, cmap='summer')
#plt.title('Correlation of stock closing price')
#
#rets = tech_rets.dropna()
#
#area = np.pi * 20
#
#plt.figure(figsize=(10, 8))
#plt.scatter(rets.mean(), rets.std(), s=area)
#plt.xlabel('Expected return')
#plt.ylabel('Risk')
#
#for label, x, y in zip(rets.columns, rets.mean(), rets.std()):
#    plt.annotate(label, xy=(x, y), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom',
#                 arrowprops=dict(arrowstyle='-', color='blue', connectionstyle='arc3,rad=-0.3'))
def report(comp):
 from datetime import datetime
 import matplotlib.pyplot as plt
 print(comp)
 df = pdr.get_data_yahoo(comp, start='2012-01-01', end=datetime.now())
 df
 
 plt.figure(figsize=(16,6))
 plt.title('Close Price History')
 plt.plot(df['Close'])
 plt.xlabel('Date', fontsize=18)
 plt.ylabel('Close Price USD ($)', fontsize=18)


 data = df.filter(['Close'])
 dates=pd.date_range(datetime.now().date(), periods=30)
 d=pd.DataFrame({'Date':dates})
 d['Close']=float(data.iloc[-1:]['Close'])
 d=d.set_index('Date')
 data=pd.concat([data,d])
 dataset = data.values
 training_data_len = int(np.ceil( len(dataset) * .95 ))
 
 training_data_len
 
 print(dataset)
 
 from sklearn.preprocessing import MinMaxScaler
 
 scaler = MinMaxScaler(feature_range=(0,1))
 scaled_data = scaler.fit_transform(dataset)
 
 scaled_data
 
 train_data = scaled_data[0:int(training_data_len), :]
 x_train = []
 y_train = []
 
 for i in range(90, len(train_data)):
     x_train.append(train_data[i-90:i, 0])
     y_train.append(train_data[i, 0])
     if i<= 91:
         print(x_train)
         print(y_train)
         print()
 
 x_train, y_train = np.array(x_train), np.array(y_train)
 
 x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
 
 from keras.models import Sequential
 from keras.layers import Dense, LSTM
 
 model = Sequential()
 model.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))
 model.add(LSTM(64, return_sequences=False))
 model.add(Dense(25))
 model.add(Dense(1))
 
 model.compile(optimizer='adam', loss='mean_squared_error')
 
 model.fit(x_train, y_train, batch_size=30, epochs=10)
 
 test_data = scaled_data[training_data_len - 90: , :]
 x_test = []
 y_test = dataset[training_data_len:, :]
 for i in range(90, len(test_data)):
     x_test.append(test_data[i-90:i, 0])
 x_test = np.array(x_test)
 
 x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))
 
 predictions = model.predict(x_test)
 predictions = scaler.inverse_transform(predictions)
 
 rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))
 rmse
 
 train = data[:training_data_len]
 valid = data[training_data_len:]
 valid['Predictions'] = predictions
 plt.figure(figsize=(16,6))
 plt.title('Model')
 plt.xlabel('Date', fontsize=18)
 plt.ylabel('Close Price USD ($)', fontsize=18)
 plt.plot(train['Close'])
 plt.plot(valid[['Close', 'Predictions']])
 plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')
 plt.savefig(os.path.join('static', 'images',comp ,'pred_chart.png'))
 stock_name = comp
 
 all_tweets = pd.read_csv('stock_tweets.csv')
 
 df1 = all_tweets[all_tweets['Stock Name'] == stock_name]
 print(df1.shape)
 df1.head()
 
 sent_df = df1.copy()
 sent_df["sentiment_score"] = ''
 sent_df["Negative"] = ''
 sent_df["Neutral"] = ''
 sent_df["Positive"] = ''
 sent_df.head()
 
 from nltk.sentiment.vader import SentimentIntensityAnalyzer
 import unicodedata
 
 import nltk
 nltk.download('vader_lexicon')
 
 # Commented out IPython magic to ensure Python compatibility.
 # %%time
 # pd.DataFrame.iteritems = pd.DataFrame.items
 # sentiment_analyzer = SentimentIntensityAnalyzer()
 # for indx, row in sent_df.T.iteritems():
 #     try:
 #         sentence_i = unicodedata.normalize('NFKD', sent_df.loc[indx, 'Tweet'])
 #         sentence_sentiment = sentiment_analyzer.polarity_scores(sentence_i)
 #         sent_df.at[indx, 'sentiment_score'] = sentence_sentiment['compound']
 #         sent_df.at[indx, 'Negative'] = sentence_sentiment['neg']
 #         sent_df.at[indx, 'Neutral'] = sentence_sentiment['neu']
 #         sent_df.at[indx, 'Positive'] = sentence_sentiment['pos']
 #     except TypeError:
 #         print (sent_df.loc[indexx, 'Tweet'])
 #         print (indx)
 #         break
 
 sent_df.head()
 
 sent_df['Date'] = pd.to_datetime(sent_df['Date'])
 sent_df['Date'] = sent_df['Date'].dt.date
 sent_df = sent_df.drop(columns=['Negative', 'Positive', 'Neutral', 'Stock Name', 'Company Name'])
 
 twitter_df = sent_df.groupby([sent_df['Date']])
 
 print(twitter_df)
 
 data
 
 from sklearn.model_selection import train_test_split
 y = np.array(data['Close'])
 X = data
 X_train, X_test, y_train, y_test = \
  train_test_split(X, y, test_size=0.3)
 
 import lightgbm as lgb
 
 
 lgb_train = lgb.Dataset(X_train, y_train)
 lgb_eval = lgb.Dataset(X_test, y_test)
 
 params = {
     'boosting_type': 'gbdt',
     'metric': 'rmse',
     'objective': 'regression',
     'n_jobs': -1,
     'seed': 236,
     'learning_rate': 0.01,
     'bagging_fraction': 0.75,
     'bagging_freq': 10,
     'colsample_bytree': 0.75}
 
 modellgb = lgb.train(params, lgb_train, num_boost_round=2500, valid_sets = [lgb_train, lgb_eval])
 
 lgb_test=valid
 lgb_test=lgb_test.drop(['Predictions'],axis=1)
 y_pred = modellgb.predict(lgb_test)
 
 predd=pd.DataFrame({'Date':lgb_test.index,'lgbm':y_pred})
 predd=predd.set_index('Date')
 tes=pd.concat([lgb_test,predd],axis=1)
 
 tes
 
 modellgb.save_model("test1.txt")
 
 tes['lstm']=valid['Predictions']
 
 tes=tes.assign(final_pred=np.where(abs(tes['Close']-tes['lstm']) < abs(tes['Close']-tes['lgbm']), tes['lstm'], tes['lgbm']))
 temp=tes.tail(30)
 temp['Close']=np.NaN
 temp.to_csv('static/images/'+comp+'/tes.csv')
 
 df = pdr.get_data_yahoo(comp, start='2012-01-01', end=datetime.now())
 df
 
 df=df.filter(['Close'])
 df=df.reset_index()
 
 df['Growth_Rate'] = df['Close'].pct_change(periods=1)*100
 
 df=df.fillna(0)
 df.tail(15).to_csv('static/images/'+comp+'/growth.csv')
 prices=pd.DataFrame()
 temp1=df.tail(30)
 temp1=temp1.drop(['Growth_Rate'],axis=1)
 prices=pd.concat([prices,temp1[temp1['Close']==min(temp1['Close'])]])
 prices=pd.concat([prices,temp1[temp1['Close']==max(temp1['Close'])]])
 prices=pd.concat([prices,temp1.iloc[[-1]]])
 np.savetxt("static/images/"+comp+"/prices.txt", prices.values, fmt='%s',encoding='utf-8')
 
 print(df)
 sent_df['Date']=pd.to_datetime(sent_df['Date'], format='%Y/%m/%d')
 hh=pd.unique(sent_df['Date'])
 a1=pd.DataFrame()
 for i in hh:
   a1=pd.concat([a1,df[df['Date']==i]])
 if a1.empty:
  return
 a1=a1.reset_index(drop=True)
 a11=a1[a1['Growth_Rate']==max(a1['Growth_Rate'])]
 a12=a1[a1['Growth_Rate']==min(a1['Growth_Rate'])]
 
 tt=np.array(a11['Date'])
 high_tweets=sent_df[sent_df['Date']==tt[0]]
 np.savetxt("static/images/"+comp+"/high_date.txt", tt, fmt='%s',encoding='utf-8')
 tt=np.array(a12['Date'])
 low_tweets=sent_df[sent_df['Date']==tt[0]]
 np.savetxt("static/images/"+comp+"/low_date.txt", tt, fmt='%s',encoding='utf-8')
 np.savetxt("static/images/"+comp+"/high_tweets.txt", high_tweets[['Tweet','sentiment_score']].values, fmt='%s',encoding='utf-8')
 high_tweets.to_csv('static/images/'+comp+'/high_tweets1.csv')
 np.savetxt("static/images/"+comp+"/low_tweets.txt", low_tweets[['Tweet','sentiment_score']].values, fmt='%s',encoding='utf-8')
 low_tweets.to_csv('static/images/'+comp+'/low_tweets1.csv')
 
 from datetime import datetime, timedelta
 tt=np.array(a11['Date'])
 start_date=pd.to_datetime(tt[0], format='%Y/%m/%d')- timedelta(days=15)
 end_date=pd.to_datetime(tt[0], format='%Y/%m/%d')+ timedelta(days=15)
 
 mask = (df['Date'] > start_date) & (df['Date'] <= end_date)
 df4=df.loc[mask]
 
 from matplotlib import pyplot as plt
 import seaborn as sns
 def _plot_series(series, series_name, series_index=0):
   palette = list(sns.palettes.mpl_palette('Dark2'))
   xs = series['Date']
   ys = series['Growth_Rate']
 
   plt.plot(xs, ys, label=series_name, color=palette[series_index % len(palette)])
 
 fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')
 df_sorted = df4.sort_values('Date', ascending=True)
 _plot_series(df_sorted, '')
 sns.despine(fig=fig, ax=ax)
 plt.xlabel('Date')
 plt.xticks(rotation=45)
 _ = plt.ylabel('Growth_Rate')
 plt.savefig(os.path.join('static', 'images',comp ,'positive_growth_rate.png'))
 
 tt=np.array(a12['Date'])
 start_date=pd.to_datetime(tt[0], format='%Y/%m/%d')- timedelta(days=15)
 end_date=pd.to_datetime(tt[0], format='%Y/%m/%d')+ timedelta(days=15)
 
 mask = (df['Date'] > start_date) & (df['Date'] <= end_date)
 df4=df.loc[mask]
 
 def _plot_series(series, series_name, series_index=0):
   palette = list(sns.palettes.mpl_palette('Dark2'))
   xs = series['Date']
   ys = series['Growth_Rate']
 
   plt.plot(xs, ys, label=series_name, color=palette[series_index % len(palette)])
 
 fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')
 df_sorted = df4.sort_values('Date', ascending=True)
 _plot_series(df_sorted, '')
 sns.despine(fig=fig, ax=ax)
 plt.xlabel('Date')
 plt.xticks(rotation=45)
 _ = plt.ylabel('Growth_Rate')
 plt.savefig(os.path.join('static', 'images',comp ,'negative_growth_rate.png'))
 return plt